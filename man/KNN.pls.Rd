% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/mstep.R
\name{KNN.pls}
\alias{KNN.pls}
\title{KNN.pls}
\arguments{
\item{X:}{training input [N,n]}

\item{Y:}{training output [N,m]}

\item{X.ts:}{test input [N.ts,n]}

\item{k:}{min number of neighbours}

\item{dist:}{type of distance: \code{euclidean, cosine}}

\item{F:}{forgetting factor}

\item{C:}{integer parameter which sets the maximum number of neighbours (Ck)}

\item{wta:}{if TRUE a winner-takes-all strategy is used;  otherwise a weigthed combination is done on the basis of the l-o-o error}

\item{Acf:}{autocorrelation function of the training series}
}
\value{
vector of N.ts predictions
}
\description{
Multioutput KNN
}
\details{
KNN.pls

Multioutput KNN for multi-step-ahed prediction. It performs a locally constant model with weighted combination of local model on the basis of partial least-squares error
}
\examples{
## Multi-step ahead time series forecasting
library(pls)
t=seq(0,400,by=0.1)
N<-length(t)
H<-1500 ## horizon prediction
TS<-sin(t)+rnorm(N,sd=0.1)
TS.tr=TS[1:(N-H)]
N.tr<-length(TS.tr)
TS.ts<-TS[(N-H+1):N]
TS.tr=array(TS.tr,c(length(TS.tr),1))
E=MakeEmbedded(TS.tr,n=3,delay=0,hor=H,1)
X<-E$inp
Y<-E$out
N<-NROW(X)
ACF.lag<-5
Y.cont<-KNN.pls(X,Y,rev(TS.tr[(N.tr-H):N.tr]))
plot(t[(N-H+1):N],TS.ts)
lines(t[(N-H+1):N],Y.cont)


## Multi-step ahead time series forecasting chaotic time series
rm(list=ls()
N<-NROW(A)
H<-200 ## horizon prediction
TS<-A[,1]
TS.tr=TS[1:(N-H)]
N.tr<-length(TS.tr)
TS.ts<-TS[(N-H+1):N]
TS.tr=array(TS.tr,c(length(TS.tr),1))
E=MakeEmbedded(TS.tr,n=16,delay=0,hor=H,1)
X<-E$inp
Y<-E$out
N<-NROW(X)

Y.cont<-KNN.pls(X,Y,rev(TS.tr[(N.tr-H):N.tr]))
plot(t[(N-H+1):N],TS.ts)
lines(t[(N-H+1):N],Y.cont)

}
\references{
\emph{Bontempi G. Ben Taieb S. Conditionally dependent strategies for multiple-step-ahead prediction in local learning, International Journal of Forecasting Volume 27, Issue 3, July–September 2011, Pages 689–699}
}
\author{
Gianluca Bontempi  \email{gbonte@ulb.ac.be}
}
