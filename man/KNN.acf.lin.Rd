% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/mstep.R
\name{KNN.acf.lin}
\alias{KNN.acf.lin}
\title{KNN.acf.lin}
\arguments{
\item{X:}{training input [N,n]}

\item{Y:}{training output [N,m]}

\item{X.ts:}{test input [N.ts,n]}

\item{k:}{min number of neighbours}

\item{dist:}{type of distance: \code{euclidean, cosine}}

\item{F:}{forgetting factor}

\item{C:}{integer parameter which sets the maximum number of neighbours (Ck)}

\item{wta:}{if TRUE a winner-takes-all strategy is used;  otherwise a weigthed combination is done on the basis of the l-o-o error}

\item{Acf:}{autocorrelation function of the training series}

\item{Reg:}{number (>1) of null terms to regularise the mean}
}
\value{
vector of N.ts predictions
}
\description{
Multioutput KNN
}
\details{
KNN.acf.lin

Multioutput KNN for multi-step-ahed prediction. It performs a locally constant model with weighted combination of local model on the basis of the autocorrelation and partial correlation properties of the training time series.
}
\examples{
## Multi-step ahead time series forecasting
require(gbcode)
t=seq(0,200,by=0.1)
N<-length(t)
H<-500 ## horizon prediction
TS<-sin(t)+rnorm(N,sd=0.1)
TS.tr=TS[1:(N-H)]
N.tr<-length(TS.tr)
TS.ts<-TS[(N-H+1):N]
TS.tr=array(TS.tr,c(length(TS.tr),1))
E=MakeEmbedded(TS.tr,n=3,delay=0,hor=H,1)
X<-E$inp
Y<-E$out
N<-NROW(X)
ACF.lag<-5
Y.cont<-KNN.acf.lin(X,Y,rev(TS.tr[(N.tr-H):N.tr]),Acf=acf(TS.tr,lag.max=ACF.lag,plot=FALSE)$acf,Pacf=pacf(TS.tr,lag.max=ACF.lag,plot=FALSE)$acf,TS=TS.tr)
plot(t[(N-H+1):N],TS.ts)
lines(t[(N-H+1):N],Y.cont)
}
\references{
\emph{Bontempi G. Ben Taieb S. Conditionally dependent strategies for multiple-step-ahead prediction in local learning, International Journal of Forecasting Volume 27, Issue 3, July–September 2011, Pages 689–699}
}
\author{
Gianluca Bontempi  \email{Gianluca.Bontempi@ulb.be}
}
