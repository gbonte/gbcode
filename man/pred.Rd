% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/mlearn.R
\name{pred}
\alias{pred}
\title{Wrapper on learning algoritmhs for regression and classification}
\usage{
pred(algo = "svm", X, Y, X.ts, classi = TRUE, ...)
}
\arguments{
\item{algo:}{learning algoritmh: \code{"lin"}: linear, \code{"rf"}: \pkg{randomForest}, \code{"svm"}: \pkg{e1071} , \code{"lazy"}: \pkg{lazy}, \code{"gbm"}: \pkg{gbm},\code{"gam"}: \pkg{gam}}

\item{X:}{training input}

\item{Y:}{training output}

\item{X.ts:}{test input}

\item{classi:}{TRUE for classification, FALSE for regression}

\item{...:}{parameters of the learning algoritmh from the original package}
}
\value{
if \code{classi=FALSE} predicted test output; if \code{classi=TRUE} a list with
\itemize{
\item{\code{pred}:}  predicted class
\item{ \code{prob}:} posteriori probability
}
}
\description{
Wrapper on learning algoritmhs
}
\examples{
## regression example
library(randomForest)
n=4
N=1000
X=array(rnorm(N*n),c(N,n))
Y=X[,1]*X[,2]+rnorm(N,sd=0.1)
Itr=sample(N,round(N/2))
Its=setdiff(1:N,Itr)
Xtr=X[Itr,]
Ytr=Y[Itr]
Xts=X[Its,]
Yts=Y[Its]
Yhat=pred("rf",Xtr,Ytr,Xts,ntree=1000, classi=FALSE)
e=Yts-Yhat
## normalized mean squared error
NMSE=mean(e^2)/var(Yts)
print(NMSE)

## classification example
n=4
N=1000
X=array(rnorm(N*n),c(N,n))
Y=numeric(N)
Y[which(X[,1]*X[,2]+rnorm(N,sd=0.1)>0)]<-1
Y=factor(Y)
Itr=sample(N,round(N/2))
Its=setdiff(1:N,Itr)
Xtr=X[Itr,]
Ytr=Y[Itr]
Xts=X[Its,]
Yts=Y[Its]
Yhat=pred("lda",Xtr,Ytr,Xts,classi=TRUE)$pred
e=as.numeric(Yts!=Yhat)
## misclassification error
MISCL=sum(e)
print(MISCL/N)

}
\author{
Gianluca Bontempi  \email{gbonte@ulb.ac.be}
}
\references{
\url{mlg.ulb.ac.be}
}

