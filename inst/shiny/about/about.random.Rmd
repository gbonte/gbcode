
# Shiny dashboard "Statistical foundations of machine learning"


## Monte Carlo illustration of r.v. properties 

### Transformation of a single r.v. 

This tab shows that by applying a functional transformation on a random
variable we obtain other random variables.
Since it is not possible to derive the analytical form of the transformed distributions,
we use a Monte Carlo strategy to sample the original r.v. and show the histograms of
different nonlinear transformations of the original r.v.

### Central limit theorem

This tab visualizes the Central Limit theorem by Monte Carlo simulation.
It shows that the sum of several random variables
(with a uniform, then non Gaussian, distribution) converge to a Gaussian distribution.

Suggested manipulations:

* use the slider "Number terms" to see how the shape changes by considering more addends.


### Operations on two r.v.s

This tab shows the results of simple operations
on two independent r.v.s by Monte Carlo simulation. This is to make evident for the
student that the sum of two r.v.s. is still a random variable.


### Linear combination of independent variables
This tab visualizes the theoretical results in the hanbdbook about
the expectation and variance of the linear combination of  two independent random variables
(null covariance), denoted by green and red.

Suggested manipulations:

* modify the values of the sliders to see the impact on the linear combination.
* simulate the setting where the two variables are identical, $a=1$ and $b=0$. What about the result? Is it what you expected? Could you explain this result?

### Linear combination of dependent variables
This tab visualizes the theoretical results in the hanbdbook about
the expectation and variance of the linear combination of  two dependent (non null covariance) random variables
${\bf x}$ and ${\bf y}$.
The dependence is established by defining an appropriate bivariate Normal joint distribution.

A generic bivariate covariance matrix may be written as 
$$ \Sigma= R S R^T $$ where $S$ and $R$ denote the scaling and rotation of 
a diagonal covariance matrix.
The scaling matrix 
$$ S=\begin{bmatrix} s_x & 0 \\ 0 & s_y  \end{bmatrix}$$ streches the x-axis and the y-axis by the
factors $s_x>0$ and $s_y>0$ respectively.

The matrix 
$$ R=\begin{bmatrix} \cos(\theta) & -\sin(\theta) \\ sin(\theta) &\cos(\theta)  \end{bmatrix}$$ 
performs a rotation of angle $\theta$.

Suggested manipulations:

* change the covariance of the matrix by acting on $s_x$, $s_y$ and $\theta$ and see the impat on the contour.
* check the good accuracy of MC approximation whatever the relation between ${\bf x}$ and ${\bf y}$
* check the good accuracy of MC approximation whatever the values of $a$ and $b$
